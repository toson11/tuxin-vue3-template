# 训练流程

### 1-数据准备

#### 1-1-数据收集（Data Collection）

##### 数据来源

- 公开数据集、爬虫、人工标注数据集等

#### 1-2-数据清洗（Data Cleaning）

##### 清洗手段

- 去除噪声
- 去除重复数据
- 纠正错别字
- 标准化
- ...

#### 1-3-数据增强（Data Augmentation）

> 作用：增加数据量，提高模型泛化能力

##### 增强手段

- 数据旋转、缩放、裁剪等

#### 1-4-数据标注（Labeling）

作用：为模型提供“正确答案”，指导模型学习

### 2-模型架构设计

#### 2-1-神经网络（Neural Network）

#### 2-2-Transformer 架构

Transformer 是当前大模型（如 GPT、BERT 等）的核心架构，是一种用于处理序列数据（比如文本、时间序列等）的神经网络结构，它特别擅长理解长文本中的不同部分如何相互关联。简而言之，**Transformer 通过让模型“看到”整个序列中的所有元素，快速而准确地理解它们之间的关系**，尤其在自然语言处理中效果非常好。

##### 2-2-1-自注意力机制（Self-Attention）

Transformer 最核心的部分是自注意力机制，它能让模型关注序列中的不同部分。比如，当处理一个句子时，模型可以同时关注句子开头的单词和结尾的单词，从而理解它们之间的关系。这样，模型不会只依赖相邻的词，而是能**看到全局信息**。

##### 2-2-2-并行处理

传统的 RNN 模型需要按顺序处理数据，而 Transformer 则可以并行处理所有数据（如句子中的所有词），这让训练速度快了很多。

##### 2-2-3-位置编码（Positional Encoding）

虽然 Transformer 能并行处理序列中的所有部分，但它仍需要知道各个单词在序列中的位置。为此，它给每个输入数据（如词）添加了位置信息，帮助模型知道“顺序”。

#### 2-3-参数（Parameters）

模型的参数就是神经网络中的**权重和偏置**，它们通过训练数据调整，以使模型学会如何对新数据进行预测。

#### 2-4-超参数（Hyperparameters）

设计模型时需要预先设置的参数，例如学习率、批次大小、网络层数等。不同的超参数组合会影响模型的表现，调优这些参数是模型训练中的一大任务。

### 3-模型训练

##### 向前传播（Forward Propagation）

模型接收到输入数据后，进行一系列的运算，逐层传递信息，最终生成一个预测输出。这是模型在推理中的正常工作过程。

##### 损失函数（Loss Function）

损失函数用于衡量模型预测结果与实际结果之间的差距，指导模型参数调整。

##### 反向传播（Backpropagation）

通过反向传播，损失值会逐层传回，更新模型的权重和偏置，以使模型的预测更准确。反向传播与梯度下降算法（Gradient Descent）一起使用，优化模型参数。

##### 优化器（Optimizer）

优化器通过计算梯度并更新模型参数。常用的优化器包括随机梯度下降（SGD）、Adam 等，Adam 在大模型训练中应用广泛，因为它能够自适应调整学习率。

##### 批次训练（Batch Training）

在处理大量数据时，模型并不是一次性处理所有数据，而是将数据分成多个批次（Batch）。批次训练可以减少内存消耗，同时让模型逐步收敛。

### 4-评估与验证

##### 验证集（Validation Set）

在训练过程中，模型会在一部分数据上进行验证，以便监控其在未见过的数据上的表现，防止过拟合。

##### 过拟合与欠拟合（Overfitting & Underfitting）

过拟合是指模型在训练数据上表现很好，但在新数据上表现不佳，原因是模型“记住”了训练数据。欠拟合则是模型未能充分学习数据中的模式，导致表现差。

##### 指标（Metrics）

评估模型的常用指标有准确率（Accuracy）、精确率（Precision）、召回率（Recall）、F1 分数等。根据不同的任务类型，选择不同的评估标准。

##### 模型调优（Model Tuning）

通过调整超参数、添加正则化、使用更复杂的模型架构等手段，对模型进行调优，以获得更好的性能。

### 5-推理与部署

##### 推理（Inference）

##### 压缩与加速（Compression & Acceleration）

##### 部署（Deployment）

##### 持续学习（Continual Learning）

### 6-反馈与迭代

##### 在线学习（Online Learning）

##### 模型监控（Model Monitoring）

# 后续预训练（Post-pretraining）

在原始大模型的基础上，通过引入大量的未标注数据（通常是纯文本数据）来进一步增强模型的语言理解能力。这个过程侧重于继续训练模型，使模型在该领域上具有更好的领域知识，但没有明确的目标任务。

# 微调（Fine-tuning）

在已经预训练好的大模型的基础上，使用特定领域或任务的数据进行进一步训练，以适应某个特定的任务。它的核心思想是利用大模型已经学到的广泛知识，在**某个特定领域进行“微调”**以达到更好的效果。

- **学习率（Learning Rate）**：微调时，通常会采用较小的学习率，以避免对模型预训练时学到的知识进行过度修改。
- **训练轮次（Epochs）**：微调一般需要较少的训练轮次，通常不会像从头训练那样进行大量的迭代，因为模型已经学到了基本的知识。
- **批次大小（Batch Size）**：可以根据硬件限制或任务复杂度进行调整。

### 监督微调（SFT，Supervised Fine-tuning）

在微调过程中，我们使用带有标签的数据集进行训练，以优化模型在特定任务上的表现。这种方法通常用于监督学习任务，如分类、回归等。

### 增量训练

与普通微调不同，增量训练（Incremental Training）更注重保持原有知识，在微调的基础上，通过较少的参数调整，进一步扩展了模型的知识，通过引入新的数据集或任务，逐步增强模型的能力。这种方法适用于需要不断更新和扩展模型知识的应用场景。

# Prompt 工程

> **Prompt 工程**（Prompt Engineering）是指在与大语言模型（如 GPT-4 等）交互时，通过精心设计和优化输入的提示词（prompt），以最大化模型输出的质量和准确性。Prompt 工程的本质是试验和优化。尝试不同的表达方式，观察模型的响应，并不断调整 Prompt，以得到最佳效果。

### Prompt 模板

### Prompt 优化

- 明确任务类型和目标
- 提供具体的示例
- 指明角色
- 分步引导：有时任务过于复杂，可以将其分解为多个步骤，逐步引导模型完成
- 加入限制
  - 设置输出格式：如果对输出有特定格式要求，明确告诉模型

### Prompt 评估

# 知识库
